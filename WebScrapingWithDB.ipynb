{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d37073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import codecs\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bec3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"De$ai6915\",\n",
    "  database=\"JobScraperDB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9165c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4696122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 1: Scraping Careers from carrerguide.com in the form subcategory->job\n",
    "        it is saved in 2 text files, \n",
    "        JobCat.txt - contains the category->job\n",
    "        JobTitles.txt - contains the job titles used for Part 2\n",
    "\"\"\"\n",
    "res=requests.get(\"https://www.careerguide.com/career-options\")\n",
    "soup=bs4.BeautifulSoup(res.text,\"lxml\") #soup object\n",
    "\n",
    "file=open(\"JobCat.txt\",'w', encoding=\"utf-8\")\n",
    "file2=open(\"JobTitles.txt\",'w', encoding='utf-8')\n",
    "\n",
    "cquery=\"insert into jobcat(Categories) values(%s)\"\n",
    "cats=\"\"\n",
    "squery=\"insert into jobsubcat(Subcategories,JobCat_Categories) values(%s,%s)\"\n",
    "titles=\"\"\n",
    "\n",
    "for j in soup.select('div.col-md-4 h2'):\n",
    "    cats+=j.getText()+\"\\n\"\n",
    "    cval=(j.getText(),)\n",
    "    try:\n",
    "        mycursor.execute(cquery,cval)\n",
    "    except:\n",
    "        pass\n",
    "    mydb.commit()\n",
    "    for i in j.next_sibling.children:\n",
    "        #print(j.getText()+\"->\"+i.findAll('a')[0].getText())\n",
    "        titles+=i.findAll('a')[0].getText()+\"\\n\"\n",
    "        sval=(i.findAll('a')[0].getText(),j.getText())\n",
    "        try:\n",
    "            mycursor.execute(squery,sval)\n",
    "        except:\n",
    "            pass\n",
    "        mydb.commit()\n",
    "#print(cats)\n",
    "mycursor.execute(squery,('Software Engineer','Engineering & Technology'))\n",
    "mydb.commit()\n",
    "file.write(cats)\n",
    "file2.write(titles)\n",
    "file.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98baad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Part 2: Searching for jobs on LinkedIn using the JobTitles.txt\n",
    "        and scraping Job Title, Company Name and Location\n",
    "'''\n",
    "\n",
    "#file=open(\"JobTitles.txt\",'r',encoding=\"utf-8\")\n",
    "#title=str(file.read())\n",
    "#title=title.split('\\n')\n",
    "#file.close()\n",
    "\n",
    "#Instead of fetching the titles from files, I make use of the DB.\n",
    "\n",
    "mycursor.execute(\"select subcategories from jobsubcat\")\n",
    "myres=mycursor.fetchall()\n",
    "ls=myres\n",
    "\n",
    "driver = webdriver.Firefox() #initialize Selenium webdriver\n",
    "\n",
    "'''for i in ls:\n",
    "        searchterm=i[0]   \n",
    "        //This is how one would iterate over all the rows returned by the SQL Query.\n",
    "        //I will demonstrate for only one so as to not get my IP blocked.                    \n",
    "'''\n",
    "searchterm=ls[0][0] #obtain the job title to search for, can be iterated for all titles\n",
    "searchterm=\"Software Engineer\"\n",
    "\n",
    "driver.get(f\"https://in.linkedin.com/jobs/search?keywords={searchterm}&location=Bengaluru%2C%20Karnataka%2C%20India&geoId=105214831&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\")\n",
    "\n",
    "page_source=driver.page_source #obtaining the page source\n",
    "\n",
    "lsoup = BeautifulSoup(page_source,features=\"html.parser\")\n",
    "lquery=\"insert into states(state) values(%s)\"\n",
    "cquery=\"insert into company(name,states_state,link) values(%s,%s,%s)\"\n",
    "jquery=\"insert into jobs(jobpos,company_name,company_states_state) values(%s,%s,%s)\"\n",
    "csquery=\"insert into company_has_jobsubcat(JobSubCat_Subcategories,Company_Name) values(%s,%s)\"\n",
    "text_titles=\"\"\n",
    "text_companies=\"\"\n",
    "text_locations=\"\"\n",
    "text_links=\"\"\n",
    "for i in lsoup.select('.job-search-card__location'):\n",
    "    text_locations+=i.getText().strip()+\"\\n\"\n",
    "    \n",
    "for i in lsoup.select('.base-search-card__info '):\n",
    "    t=i.contents[1].contents[0].strip()+\"\\n\"\n",
    "    text_titles+=t\n",
    "    #print(t)\n",
    "    try:\n",
    "        comp=i.contents[3].contents[1].contents[0].strip()+\"\\n\"\n",
    "        text_companies+=comp\n",
    "        text_links+=i.find_all('a')[0]['href']+\"\\n\"\n",
    "        #print(comp+\"\\n\")\n",
    "    except:\n",
    "        comp=i.contents[3].contents[0].strip()+\"\\n\"\n",
    "        text_companies+=comp\n",
    "        text_links+=\"NULL\"+\"\\n\"\n",
    "        #print(comp+\"\\n\")\n",
    "        continue\n",
    "\n",
    "for i in lsoup.select('.hidden-nested-link'):\n",
    "    text_links+=i['href']+\"\\n\"\n",
    "    \n",
    "text_links=text_links.split(\"\\n\")\n",
    "text_titles=text_titles.split(\"\\n\")\n",
    "text_companies=text_companies.split(\"\\n\")\n",
    "text_locations=text_locations.split(\"\\n\")\n",
    "\n",
    "for i in range(0,len(text_titles)):\n",
    "    lval=(text_locations[i],)\n",
    "    cval=(text_companies[i],text_locations[i],text_links[i])\n",
    "    jval=(text_titles[i],text_companies[i],text_locations[i])\n",
    "    csval=(searchterm,text_companies[i])\n",
    "    try:\n",
    "        mycursor.execute(lquery,lval)\n",
    "    except:\n",
    "        pass\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        mycursor.execute(cquery,cval)\n",
    "    except:\n",
    "        pass\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        mycursor.execute(jquery,jval)\n",
    "    except:\n",
    "        pass\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        mycursor.execute(csquery,csval)\n",
    "    except:\n",
    "        pass\n",
    "    mydb.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "504d21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://in.linkedin.com/company/stockgro?trk=public_jobs_jserp-result_job-search-card-subtitle\n",
      "<html><head>\n",
      "<script type=\"text/javascript\">\n",
      "window.onload = function() {\n",
      "  // Parse the tracking code from cookies.\n",
      "  var trk = \"bf\";\n",
      "  var trkInfo = \"bf\";\n",
      "  var cookies = document.cookie.split(\"; \");\n",
      "  for (var i = 0; i < cookies.length; ++i) {\n",
      "    if ((cookies[i].indexOf(\"trkCode=\") == 0) && (cookies[i].length > 8)) {\n",
      "      trk = cookies[i].substring(8);\n",
      "    }\n",
      "    else if ((cookies[i].indexOf(\"trkInfo=\") == 0) && (cookies[i].length > 8)) {\n",
      "      trkInfo = cookies[i].substring(8);\n",
      "    }\n",
      "  }\n",
      "\n",
      "  if (window.location.protocol == \"http:\") {\n",
      "    // If \"sl\" cookie is set, redirect to https.\n",
      "    for (var i = 0; i < cookies.length; ++i) {\n",
      "      if ((cookies[i].indexOf(\"sl=\") == 0) && (cookies[i].length > 3)) {\n",
      "        window.location.href = \"https:\" + window.location.href.substring(window.location.protocol.length);\n",
      "        return;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  // Get the new domain. For international domains such as\n",
      "  // fr.linkedin.com, we convert it to www.linkedin.com\n",
      "  // treat .cn similar to .com here\n",
      "  var domain = location.host;\n",
      "  if (domain != \"www.linkedin.com\" && domain != \"www.linkedin.cn\") {\n",
      "    var subdomainIndex = location.host.indexOf(\".linkedin\");\n",
      "    if (subdomainIndex != -1) {\n",
      "      domain = \"www\" + location.host.substring(subdomainIndex);\n",
      "    }\n",
      "  }\n",
      "\n",
      "  window.location.href = \"https://\" + domain + \"/authwall?trk=\" + trk + \"&trkInfo=\" + trkInfo +\n",
      "      \"&original_referer=\" + document.referrer.substr(0, 200) +\n",
      "      \"&sessionRedirect=\" + encodeURIComponent(window.location.href);\n",
      "}\n",
      "</script>\n",
      "</head></html>\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m lsoup \u001b[38;5;241m=\u001b[39m bs4\u001b[38;5;241m.\u001b[39mBeautifulSoup(res\u001b[38;5;241m.\u001b[39mtext,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(lsoup)\n\u001b[1;32m---> 11\u001b[0m desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43mlsoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.about-us__description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgetText()\n\u001b[0;32m     12\u001b[0m dval\u001b[38;5;241m=\u001b[39mdesc\n\u001b[0;32m     13\u001b[0m mycursor\u001b[38;5;241m.\u001b[39mexecute(dquery,dval)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"select link from company\")\n",
    "myres=mycursor.fetchall()\n",
    "ls=myres\n",
    "#driv=webdriver.Firefox()\n",
    "dquery=\"insert into company(desc) values(%s) where company.link={0}\".format(ls[0][0])\n",
    "res=requests.get(\"https://in.linkedin.com/company/stockgro?trk=public_jobs_jserp-result_job-search-card-subtitle\")\n",
    "print(ls[0][0])\n",
    "page_source=driver.page_source\n",
    "lsoup = bs4.BeautifulSoup(res.text,\"lxml\")\n",
    "print(lsoup)\n",
    "desc=\"Description:\"+lsoup.select('.about-us__description')[0].getText()\n",
    "dval=desc\n",
    "mycursor.execute(dquery,dval)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7352b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.close()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d7e7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
